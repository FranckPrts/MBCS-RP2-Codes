{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair / Bert / Sementic similarity\n",
    "- [Hugging facer repo](https://huggingface.co/models?library=flair&sort=downloads)\n",
    "- [Flair embedinggs](https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class\n",
    "from utils.speech_sw import read_dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Transcripts/\"\n",
    "path += \"SAMPLE.json\"\n",
    "\n",
    "# Innit class\n",
    "speech = read_dialogue(path, sw_min=None, sw_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefits\n",
      "from\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "speech.select_sw(79.3, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech.dialogue is a dict \n",
    "print(speech.dialogue.keys())\n",
    "print(len(speech.dialogue[\"results\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 14 results available in our sample. \n",
    "\n",
    "13 sentences, each containing a list of all the \n",
    "\n",
    "- confidence\n",
    "- startTime\n",
    "- endTime\n",
    "- word\n",
    "\n",
    "\n",
    "1 list of all the words, with their   <-- This is our element of interest\n",
    "\n",
    "- confidence\n",
    "- startTime\n",
    "- endTime\n",
    "- **speakerTag**\n",
    "- word\n",
    "\n",
    "Because we're interrested in sampling words that fall within a time window, we'll use the last element of the JSON which provide the following (confidence, startTime, endTime, speakerTag,Â word)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many word we have and let's also print the 350th word information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There is %i in that transcript\" % len(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"]))\n",
    "print(\"Here are the infos for the 349th word\")\n",
    "print(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"][349])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the 13 individual sentence object\n",
    "print(\"Each available keys for each sentence\")\n",
    "print(speech.dialogue[\"results\"][1].keys())\n",
    "\n",
    "print(\"\\nThere is %i alternative in our transcription\" % len(speech.dialogue[\"results\"][0][\"alternatives\"]))\n",
    "print(\"This alternative has %i keys \" % len(speech.dialogue[\"results\"][0][\"alternatives\"][0].keys()))\n",
    "print('Which are:')\n",
    "print(speech.dialogue[\"results\"][0][\"alternatives\"][0].keys())\n",
    "\n",
    "print(\"\\nWith 'words' being a dict with all the sentence's words and their attributes\")\n",
    "speech.dialogue[\"results\"][0][\"alternatives\"][0][\"words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = TransformerWordEmbeddings()\n",
    "\n",
    "sent = Sentence('a random sentence is typed here.', use_tokenizer=True)\n",
    "embedding.embed(sent)\n",
    "\n",
    "sent_em = np.array([s.embedding.cpu().numpy() for s in sent])\n",
    "\n",
    "sent_avg = np.mean(sent_em, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

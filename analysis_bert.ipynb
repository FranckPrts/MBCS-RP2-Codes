{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON transcripts / Bert / Semantic similarity\n",
    "- [Hugging facer repo](https://huggingface.co/models?library=flair&sort=downloads)\n",
    "- [Flair embedinggs](https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class\n",
    "from utils.speech_sw import read_dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the class [here](https://github.com/FranckPrts/MBCS-RP2-Codes/blob/master/utils/speech_sw.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Transcripts/\"\n",
    "path += \"SAMPLE.json\"\n",
    "\n",
    "# Innit class\n",
    "speech = read_dialogue(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefits\n",
      "from\n",
      "the\n",
      "American\n",
      "Military\n"
     ]
    }
   ],
   "source": [
    "speech.select_sw(79.3, 82.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['results'])\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# speech.dialogue is a dict \n",
    "print(speech.dialogue.keys())\n",
    "print(len(speech.dialogue[\"results\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 14 results available in our sample. \n",
    "\n",
    "13 sentences, each containing a list of all the \n",
    "\n",
    "- confidence\n",
    "- startTime\n",
    "- endTime\n",
    "- word\n",
    "\n",
    "\n",
    "1 list of all the words, with their   <-- This is our element of interest\n",
    "\n",
    "- confidence\n",
    "- startTime\n",
    "- endTime\n",
    "- **speakerTag**\n",
    "- word\n",
    "\n",
    "Because we're interrested in sampling words that fall within a time window, we'll use the last element of the JSON which provide the following (confidence, startTime, endTime, speakerTag,Â word)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many word we have and let's also print the 350th word information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 433 in that transcript\n",
      "Here are the infos for the 349th word\n",
      "{'confidence': 0.88791323, 'endTime': '236.800s', 'speakerTag': 2, 'startTime': '235.200s', 'word': 'story'}\n"
     ]
    }
   ],
   "source": [
    "print(\"There is %i in that transcript\" % len(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"]))\n",
    "print(\"Here are the infos for the 349th word\")\n",
    "print(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"][349])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each available keys for each sentence\n",
      "dict_keys(['alternatives', 'languageCode', 'resultEndTime'])\n",
      "\n",
      "There is 1 alternative in our transcription\n",
      "This alternative has 3 keys \n",
      "Which are:\n",
      "dict_keys(['confidence', 'transcript', 'words'])\n",
      "\n",
      "With 'words' being a dict with all the sentence's words and their attributes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'confidence': 0.92412996,\n",
       "  'endTime': '5.900s',\n",
       "  'startTime': '2s',\n",
       "  'word': 'the'},\n",
       " {'confidence': 0.93932408,\n",
       "  'endTime': '6.100s',\n",
       "  'startTime': '5.900s',\n",
       "  'word': 'other'},\n",
       " {'confidence': 1, 'endTime': '6.300s', 'startTime': '6.100s', 'word': 'day'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the 13 individual sentence object\n",
    "print(\"Each available keys for each sentence\")\n",
    "print(speech.dialogue[\"results\"][1].keys())\n",
    "\n",
    "print(\"\\nThere is %i alternative in our transcription\" % len(speech.dialogue[\"results\"][0][\"alternatives\"]))\n",
    "print(\"This alternative has %i keys \" % len(speech.dialogue[\"results\"][0][\"alternatives\"][0].keys()))\n",
    "print('Which are:')\n",
    "print(speech.dialogue[\"results\"][0][\"alternatives\"][0].keys())\n",
    "\n",
    "print(\"\\nWith 'words' being a dict with all the sentence's words and their attributes\")\n",
    "speech.dialogue[\"results\"][0][\"alternatives\"][0][\"words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = TransformerWordEmbeddings()\n",
    "\n",
    "sent = Sentence('a random sentence is typed here.', use_tokenizer=True)\n",
    "embedding.embed(sent)\n",
    "\n",
    "sent_em = np.array([s.embedding.cpu().numpy() for s in sent])\n",
    "\n",
    "sent_avg = np.mean(sent_em, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flair.data.Sentence"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON transcripts / Bert / Semantic similarity\n",
    "- [Hugging facer repo](https://huggingface.co/models?library=flair&sort=downloads)\n",
    "- [Flair embedinggs](https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code of the class used here --> [link](https://github.com/FranckPrts/MBCS-RP2-Codes/blob/master/utils/speech_sw.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class\n",
    "from utils.speech_sw import read_dialogue\n",
    "\n",
    "# Define path to transcripts\n",
    "path = \"../Transcripts/\"\n",
    "path += \"SAMPLE.json\"\n",
    "\n",
    "# Innit class\n",
    "speech = read_dialogue(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting dialogue extraction ...\n",
      ">> Time window [28.600000 - 42.000000] \n",
      "[29.100000 - 29.400000] \tSpeaker: 2 \t\tWord: you\n",
      "[29.400000 - 29.500000] \tSpeaker: 2 \t\tWord: don't\n",
      "[29.500000 - 29.700000] \tSpeaker: 2 \t\tWord: want\n",
      "[29.700000 - 29.800000] \tSpeaker: 2 \t\tWord: to\n",
      "[29.800000 - 30.000000] \tSpeaker: 2 \t\tWord: push\n",
      "[30.000000 - 30.100000] \tSpeaker: 2 \t\tWord: it\n",
      "[30.100000 - 30.200000] \tSpeaker: 2 \t\tWord: in\n",
      "[30.200000 - 32.600000] \tSpeaker: 2 \t\tWord: so\n",
      "[32.600000 - 33.000000] \tSpeaker: 2 \t\tWord: she\n",
      "[33.000000 - 33.100000] \tSpeaker: 2 \t\tWord: called\n",
      "[33.100000 - 33.300000] \tSpeaker: 2 \t\tWord: me\n",
      "[33.300000 - 33.400000] \tSpeaker: 2 \t\tWord: and\n",
      "[33.400000 - 33.500000] \tSpeaker: 2 \t\tWord: I\n",
      "[33.500000 - 33.700000] \tSpeaker: 2 \t\tWord: didn't\n",
      "[33.700000 - 33.800000] \tSpeaker: 2 \t\tWord: know\n",
      "[33.800000 - 33.800000] \tSpeaker: 2 \t\tWord: she\n",
      "[33.800000 - 34.000000] \tSpeaker: 2 \t\tWord: had\n",
      "[34.000000 - 34.500000] \tSpeaker: 2 \t\tWord: calls\n",
      "[34.500000 - 34.600000] \tSpeaker: 2 \t\tWord: cuz\n",
      "[34.600000 - 34.700000] \tSpeaker: 2 \t\tWord: he\n",
      "[34.700000 - 34.900000] \tSpeaker: 2 \t\tWord: was\n",
      "[34.900000 - 35.200000] \tSpeaker: 2 \t\tWord: talking\n",
      "[35.200000 - 35.300000] \tSpeaker: 2 \t\tWord: my\n",
      "[35.300000 - 35.400000] \tSpeaker: 2 \t\tWord: ear\n",
      "[35.400000 - 35.700000] \tSpeaker: 2 \t\tWord: off\n",
      "[35.700000 - 36.100000] \tSpeaker: 2 \t\tWord: with\n",
      "[36.100000 - 36.400000] \tSpeaker: 2 \t\tWord: my\n",
      "[36.400000 - 36.600000] \tSpeaker: 2 \t\tWord: home\n",
      "[37.800000 - 38.600000] \tSpeaker: 2 \t\tWord: DaVinci\n",
      "[38.600000 - 40.700000] \tSpeaker: 1 \t\tWord: she\n",
      "[40.700000 - 41.000000] \tSpeaker: 1 \t\tWord: like\n",
      "[41.000000 - 41.700000] \tSpeaker: 2 \t\tWord: come\n",
      "[41.700000 - 41.800000] \tSpeaker: 2 \t\tWord: to\n",
      "[41.800000 - 41.900000] \tSpeaker: 2 \t\tWord: my\n",
      ">> Dialogue extracted.\n"
     ]
    }
   ],
   "source": [
    "speech.select_sw(sw_min=28.6, sw_max=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the contribution of each participant to the dialogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from speaker 1 :  ['she', 'like']\n",
      "Text from speaker 2 :  ['you', \"don't\", 'want', 'to', 'push', 'it', 'in', 'so', 'she', 'called', 'me', 'and', 'I', \"didn't\", 'know', 'she', 'had', 'calls', 'cuz', 'he', 'was', 'talking', 'my', 'ear', 'off', 'with', 'my', 'home', 'DaVinci', 'come', 'to', 'my']\n"
     ]
    }
   ],
   "source": [
    "print(\"Text from speaker 1 : \", speech.sub1_speech_list)\n",
    "print(\"Text from speaker 2 : \", speech.sub2_speech_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now embed these two dialogue segment using `TransformerWordEmbeddings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speech.sub2_speech_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting dialogue embeding w/ w2v ...\n",
      "\n",
      ">> Embeding S1 ...\n",
      "embeding:  she\n",
      "embeding:  like\n",
      ">> Done.\n",
      "\n",
      ">> Embeding S2 ...\n",
      "embeding:  you\n",
      "embeding:  don't\n",
      "embeding:  want\n",
      "embeding:  to\n",
      "> Word not embeded : to\n",
      "> Error: \"Key 'to' not present\"\n",
      "embeding:  push\n",
      "embeding:  it\n",
      "embeding:  in\n",
      "embeding:  so\n",
      "embeding:  she\n",
      "embeding:  called\n",
      "embeding:  me\n",
      "embeding:  and\n",
      "> Word not embeded : and\n",
      "> Error: \"Key 'and' not present\"\n",
      "embeding:  I\n",
      "embeding:  didn't\n",
      "embeding:  know\n",
      "embeding:  she\n",
      "embeding:  had\n",
      "embeding:  calls\n",
      "embeding:  cuz\n",
      "embeding:  he\n",
      "embeding:  was\n",
      "embeding:  talking\n",
      "embeding:  my\n",
      "embeding:  ear\n",
      "embeding:  off\n",
      "embeding:  with\n",
      "embeding:  my\n",
      "embeding:  home\n",
      "embeding:  DaVinci\n",
      "embeding:  come\n",
      "embeding:  to\n",
      "> Word not embeded : to\n",
      "> Error: \"Key 'to' not present\"\n",
      "embeding:  my\n",
      ">> Done.\n",
      ">> Dialogue embeded.\n"
     ]
    }
   ],
   "source": [
    "speech.embed_dialogue_wtov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 'S2', 'and': 'S2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech.not_embeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speech.sub2_speech_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7117323279380798"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech.compute_semantic_similarity()\n",
    "speech.sem_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech.dialogue is a dict \n",
    "print(speech.dialogue.keys())\n",
    "print(len(speech.dialogue[\"results\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 14 results available in our sample. \n",
    "\n",
    "13 sentences, each containing a list of all the \n",
    "\n",
    "- confidence\n",
    "- startTime\n",
    "- endTime\n",
    "- word\n",
    "\n",
    "\n",
    "1 list of all the words, with their   <-- This is our element of interest\n",
    "\n",
    "- confidence\n",
    "- startTime\n",
    "- endTime\n",
    "- **speakerTag**\n",
    "- word\n",
    "\n",
    "Because we're interrested in sampling words that fall within a time window, we'll use the last element of the JSON which provide the following (confidence, startTime, endTime, speakerTag,Â word)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many word we have and let's also print the 350th word information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There is %i in that transcript\" % len(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"]))\n",
    "print(\"Here are the infos for the 349th word\")\n",
    "print(speech.dialogue[\"results\"][13][\"alternatives\"][0][\"words\"][349])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the 13 individual sentence object\n",
    "print(\"Each available keys for each sentence\")\n",
    "print(speech.dialogue[\"results\"][1].keys())\n",
    "\n",
    "print(\"\\nThere is %i alternative in our transcription\" % len(speech.dialogue[\"results\"][0][\"alternatives\"]))\n",
    "print(\"This alternative has %i keys \" % len(speech.dialogue[\"results\"][0][\"alternatives\"][0].keys()))\n",
    "print('Which are:')\n",
    "print(speech.dialogue[\"results\"][0][\"alternatives\"][0].keys())\n",
    "\n",
    "print(\"\\nWith 'words' being a dict with all the sentence's words and their attributes\")\n",
    "speech.dialogue[\"results\"][0][\"alternatives\"][0][\"words\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
